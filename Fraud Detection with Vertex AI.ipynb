{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f30b97-318a-4916-b746-d2e9e534e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parts of this notebook have been omitted before hosting it on this repo.\n",
    "# This notebook serves as a sample notebook for the logic behind the work that we have established, and not intended to be executed.\n",
    "# If you want to execute it, you need to create the following services: Cloud Storage, BQML and Vextex AI notebook, and chnage some parts of the source code.\n",
    "# Ongoing work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1d909-a8b0-4233-ad3d-372cdd60cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "\n",
    "import functools\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f06cb-eb24-4013-bc6b-5bef0a71861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECT_ID = ***\n",
    "DATASET_GCP_PROJECT_ID = GCP_PROJECT_ID # A copy of the data is saved in the user project\n",
    "DATASET_ID = 'tfe_codelab'\n",
    "TRAIN_TABLE_ID = 'ulb_fraud_detection_train'\n",
    "VAL_TABLE_ID = 'ulb_fraud_detection_val'\n",
    "TEST_TABLE_ID = 'ulb_fraud_detection_test'\n",
    "\n",
    "FEATURES = ['Time','V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "LABEL='Class'\n",
    "DTYPES=[tf.float64] * len(FEATURES) + [tf.int64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb8f2d-b6c4-4b57-9fda-aa360d56a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = BigQueryClient()\n",
    "\n",
    "def read_session(TABLE_ID):\n",
    "    return client.read_session(\n",
    "        \"projects/\" + GCP_PROJECT_ID, DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "        FEATURES + [LABEL], DTYPES, requested_streams=2\n",
    ")\n",
    "\n",
    "def extract_labels(input_dict):\n",
    "  features = dict(input_dict)\n",
    "  label = tf.cast(features.pop(LABEL), tf.float64)\n",
    "  return (features, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f5a0e-8618-4eb0-b085-7b2a226b508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "raw_train_data = read_session(TRAIN_TABLE_ID).parallel_read_rows().map(extract_labels).batch(BATCH_SIZE)\n",
    "raw_val_data = read_session(VAL_TABLE_ID).parallel_read_rows().map(extract_labels).batch(BATCH_SIZE)\n",
    "raw_test_data = read_session(TEST_TABLE_ID).parallel_read_rows().map(extract_labels).batch(BATCH_SIZE)\n",
    "\n",
    "next(iter(raw_train_data)) # Print first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3f156-0f06-4c0d-a5b6-3ed9722af517",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEANS = [94816.7387536405, 0.0011219465482001268, -0.0021445914636999603, -0.002317402958335562,\n",
    "         -0.002525792169927835, -0.002136576923287782, -3.7586818983702984, 8.135919975738768E-4,\n",
    "         -0.0015535579268265718, 0.001436137140461279, -0.0012193712736681508, -4.5364970422902533E-4,\n",
    "         -4.6175444671576083E-4, 9.92177789685366E-4, 0.002366229151475428, 6.710217226762278E-4,\n",
    "         0.0010325807119864225, 2.557260815835395E-4, -2.0804190062322664E-4, -5.057391100818653E-4,\n",
    "         -3.452114767842334E-6, 1.0145936326270006E-4, 3.839214074518535E-4, 2.2061197469126577E-4,\n",
    "         -1.5601580596677608E-4, -8.235017846415852E-4, -7.298316615408554E-4, -6.898459943652376E-5,\n",
    "         4.724125688297753E-5, 88.73235686453587]\n",
    "\n",
    "def norm_data(mean, data):\n",
    "  data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
    "  return tf.reshape(data, [-1, 1])\n",
    "\n",
    "numeric_columns = []\n",
    "\n",
    "for i, feature in enumerate(FEATURES):\n",
    "  num_col = tf.feature_column.numeric_column(feature, normalizer_fn=functools.partial(norm_data, MEANS[i]))\n",
    "  numeric_columns.append(num_col)\n",
    "\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54248c26-c695-4beb-9848-eb5f0ee9a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[None]),    \n",
    "  \n",
    "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
    "                      strides=1, padding=\"causal\",\n",
    "                      activation=\"relu\",\n",
    "                      input_shape=[None, 1]),\n",
    "\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True)),\n",
    "\n",
    "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "  \n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 400.0)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history_cnn_bigru = model.fit(dataset, epochs=150)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
